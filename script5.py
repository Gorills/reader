import requests
from requests_html import HTMLSession
import random
import time
import logging
from colorama import init, Fore, Style
from multiprocessing import Pool
import os

init()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# üìå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOOK_URL = "https://author.today/reader/89419"
CHAPTER_IDS = [704052, 705009, 707495, 707877, 708134, 709579]
CHAPTER_DISTRIBUTION = [50, 30, 10, 5, 3, 1]

# ‚è≥ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
MIN_READING_TIME = 240
MAX_READING_TIME = 360
MIN_SESSION_TIME = 360
MAX_SESSION_TIME = 2400
SESSION_DELAY = (5, 10)
NUM_SESSIONS = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π

def get_proxy_list():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏ –∏–∑ API"""
    api_url = "https://proxy-bunker.com/api2.php"
    try:
        response = requests.get(api_url, timeout=10)
        response.raise_for_status()
        proxy_list = response.text.strip().split('\n')
        proxy_list = [f"http://{proxy}" if not proxy.startswith("http") else proxy for proxy in proxy_list]
        additional_proxies = []
        proxy_list.extend(additional_proxies)
        logger.info(f"{Fore.GREEN}–ü–æ–ª—É—á–µ–Ω–æ {len(proxy_list)} –ø—Ä–æ–∫—Å–∏ –∏–∑ API –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞{Style.RESET_ALL}")
        return proxy_list
    except requests.RequestException as e:
        logger.error(f"{Fore.RED}–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏: {e}{Style.RESET_ALL}")
        return []

def test_proxy(proxy, test_url="https://www.google.com"):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å"""
    session = HTMLSession()
    try:
        response = session.get(test_url, proxies={"http": proxy, "https": proxy}, timeout=10)
        response.html.render()  # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ JavaScript
        logger.info(f"{Fore.GREEN}–ü—Ä–æ–∫—Å–∏ {proxy} —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ{Style.RESET_ALL}")
        return True
    except Exception as e:
        logger.warning(f"{Fore.YELLOW}–ü—Ä–æ–∫—Å–∏ {proxy} –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}{Style.RESET_ALL}")
        return False

def read_chapter(chapter_url, session, remaining_time):
    """–ß–∏—Ç–∞–µ–º –≥–ª–∞–≤—É (–∏–º–∏—Ç–∞—Ü–∏—è —á—Ç–µ–Ω–∏—è)"""
    try:
        response = session.get(chapter_url, timeout=10)
        response.html.render()  # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ JavaScript
        content = response.html.find("#reader > div.reader-content.hidden-print", first=True)
        if not content:
            logger.error(f"{Fore.RED}‚ùå –ö–æ–Ω—Ç–µ–Ω—Ç –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ {chapter_url}{Style.RESET_ALL}")
            return 0

        reading_time = min(random.uniform(MIN_READING_TIME, MAX_READING_TIME), remaining_time)
        logger.info(f"{Fore.YELLOW}üìñ –ß–∏—Ç–∞–µ–º –≥–ª–∞–≤—É: {chapter_url}, –≤—Ä–µ–º—è: {reading_time:.1f} —Å–µ–∫{Style.RESET_ALL}")
        time.sleep(reading_time)
        logger.info(f"{Fore.GREEN}‚úÖ –ì–ª–∞–≤–∞ –ø—Ä–æ—á–∏—Ç–∞–Ω–∞: {chapter_url}{Style.RESET_ALL}")
        return reading_time
    except Exception as e:
        logger.error(f"{Fore.RED}‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –≥–ª–∞–≤—ã {chapter_url}: {e}{Style.RESET_ALL}")
        return 0

def simulate_session(session_id):
    """–ò–º–∏—Ç–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–µ—Å—Å–∏–∏"""
    try:
        proxy_list = get_proxy_list()
        working_proxy = None
        session = HTMLSession()

        for proxy in random.sample(proxy_list, min(len(proxy_list), 5)):
            if test_proxy(proxy):
                working_proxy = proxy
                session.proxies = {"http": working_proxy, "https": working_proxy}
                break

        if not working_proxy and proxy_list:
            logger.warning(f"{Fore.YELLOW}‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏{Style.RESET_ALL}")
        if working_proxy:
            logger.info(f"{Fore.CYAN}–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {working_proxy} –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}{Style.RESET_ALL}")

        session_time = random.uniform(MIN_SESSION_TIME, MAX_SESSION_TIME)
        remaining_time = session_time

        logger.info(f"{Fore.MAGENTA}üïµÔ∏è –ù–∞—á–∏–Ω–∞–µ–º —Å–µ—Å—Å–∏—é {session_id}, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {session_time:.1f} —Å–µ–∫{Style.RESET_ALL}")

        chapter_urls = [f"{BOOK_URL}/{chapter_id}" for chapter_id in CHAPTER_IDS]
        weighted_chapters = random.choices(chapter_urls, weights=CHAPTER_DISTRIBUTION, k=len(chapter_urls))

        for chapter_url in weighted_chapters:
            if remaining_time <= 0:
                break
            spent_time = read_chapter(chapter_url, session, remaining_time)
            remaining_time -= spent_time

        logger.info(f"{Fore.BLUE}üìå –°–µ—Å—Å–∏—è {session_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Å—Ç–∞–ª–æ—Å—å –≤—Ä–µ–º–µ–Ω–∏: {remaining_time:.1f} —Å–µ–∫{Style.RESET_ALL}")
    except Exception as e:
        logger.error(f"{Fore.RED}‚ùå –û—à–∏–±–∫–∞ –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}{Style.RESET_ALL}")

def main():
    """–ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ—Å—Å–∏–π —á–µ—Ä–µ–∑ multiprocessing"""
    with Pool(processes=NUM_SESSIONS) as pool:
        pool.map(simulate_session, range(NUM_SESSIONS))

if __name__ == "__main__":
    main()